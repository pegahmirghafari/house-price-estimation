{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EZ-Pickle for the Flask Lesson\n",
    "___\n",
    "\n",
    "The `pickle` library allows us to serialize any python object. This saves the object exactly as it sits in our code to an actual file that we can load up later (or even send to someone else). This process can be applied in many ways, it is used here to save a trained model for use later on in another script.\n",
    "\n",
    "Since everything in python is an object, (almost) anything can be serialized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imports**\n",
    "\n",
    "Pickle is a python built-in! Simply `import pickle` and you are good to go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd, numpy as np\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, RidgeCV, LassoCV, LassoLars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read in data and fit a model**\n",
    "\n",
    "We are fitting a linear regression model on the Ames `train.csv`. This model will power a web form in the flask demo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('ames.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       3\n",
       "1       4\n",
       "2       3\n",
       "3       3\n",
       "4       3\n",
       "       ..\n",
       "2046    3\n",
       "2047    1\n",
       "2048    3\n",
       "2049    3\n",
       "2050    3\n",
       "Name: Bedroom AbvGr, Length: 2051, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Bedroom AbvGr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model explains 80.53% of the variance\n",
      "-----\n",
      "Coefficients:\n",
      "[      0.      -88540.4107   18291.6169 -177973.794   -50464.6328\n",
      "  148739.3374  130088.957    52927.5489   12953.5379   29503.5288\n",
      "   15236.6755   62479.4057   -1269.8859   17602.2609    3751.4623\n",
      "    7874.6763  -41386.4002   -4190.6691    2577.8679  -29679.8823\n",
      "  174671.5905    7391.0331  -16341.3826   78268.3088    -451.4726\n",
      " -142161.467  -136334.1701   10469.1166]\n"
     ]
    }
   ],
   "source": [
    "# read in the data\n",
    "df = pd.read_csv('ames.csv')\n",
    "\n",
    "# pick some columns, drop the nulls.\n",
    "good_cols = ['Overall Qual', 'Full Bath', 'Garage Area', 'Lot Area','Year Built','Bedroom AbvGr']\n",
    "df.dropna(subset=good_cols, inplace=True)\n",
    "\n",
    "# set up feature matrix and target vector\n",
    "X = df[good_cols]\n",
    "y = df['SalePrice']\n",
    "\n",
    "\n",
    "\n",
    "py= PolynomialFeatures()\n",
    "py.fit(X)\n",
    "X = py.transform(X)\n",
    "\n",
    "\n",
    "\n",
    "ss= StandardScaler()\n",
    "ss.fit(X)\n",
    "X= ss.transform(X)\n",
    "# instantiate the model\n",
    "\n",
    "model_to_be_pickled = LinearRegression()\n",
    "\n",
    "# fit the model\n",
    "model_to_be_pickled.fit(X,y)\n",
    "\n",
    "# print out the score and coefficients\n",
    "print(f'The model explains {100*model_to_be_pickled.score(X,y):.2f}% of the variance' + '\\n-----\\n' + 'Coefficients:')\n",
    "print( np.round(model_to_be_pickled.coef_, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pickling**  \n",
    "Everything above this was just 'normal' modeling. Now we will actually save the model to a file with the '.p' extension\n",
    "- `open(filename, permissions)`: allows us to write to a file on our computer, can be used in many different ways. \n",
    "- `pickle.dump(object, file)`: serializes an object to an open file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put the two functions above together, using 'write binary' permissions\n",
    "pickle.dump(model_to_be_pickled, open('model.p', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check our work**\n",
    "\n",
    "Let's read in our model and check the score/coefficients.\n",
    "- `pickle.load(file)`: de-serializes the stored object back into a variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model explains 80.53% of the variance\n",
      "-----\n",
      "Coefficients:\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'columns'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-29df544471ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'The model explains {100*model_that_was_pickled.score(X,y):.2f}% of the variance'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\n-----\\n'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'Coefficients:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_that_was_pickled\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'columns'"
     ]
    }
   ],
   "source": [
    "# use the above function with open() and 'read binary' permissions to get our model back\n",
    "model_that_was_pickled = pickle.load(open('model.p', 'rb'))\n",
    "\n",
    "print(f'The model explains {100*model_that_was_pickled.score(X,y):.2f}% of the variance' + '\\n-----\\n' + 'Coefficients:')\n",
    "print(dict(zip(list(X.columns), np.round(model_that_was_pickled.coef_, 4))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
